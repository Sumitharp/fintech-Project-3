{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date2 = \"2021-07-16\"\n",
    "end_date2 = \"2021-07-28\"\n",
    "# Fetch historic data from yfiance\n",
    "#df_historic2015_2019 = yfinance_tickers_data(\"NG=F\", start_date2, end_date2, drop_extra_cols = True )\n",
    "df = yf.download(\"ba\", start=\"2017-01-01\", end=\"2021-07-29\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the stock quote\n",
    "#df = web.DataReader('BA', data_source='yahoo', start='2021-07-16', end='2021-07-28') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show data\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows and colums inthe data set\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = df.reset_index()\n",
    "fig = px.line(df, x='Date', y=\"Close\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Dash is running on http://127.0.0.1:8070/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8070/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash/deps/polyfill@7.v1_21_0m1627149480.12.1.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash/deps/prop-types@15.v1_21_0m1627149480.7.2.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash/deps/react-dom@16.v1_21_0m1627149480.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash_html_components/dash_html_components.v1_1_4m1627149479.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash/deps/react@16.v1_21_0m1627149480.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash_core_components/dash_core_components-shared.v1_17_1m1627149480.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash_core_components/dash_core_components.v1_17_1m1627149480.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:56] \"GET /_dash-component-suites/dash/dash-renderer/build/dash_renderer.v1_21_0m1627149480.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:57] \"GET /_favicon.ico?v=1.21.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:57] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:57] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:57] \"GET /_dash-component-suites/dash_core_components/async-graph.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:57] \"GET /_favicon.ico?v=1.21.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Jul/2021 20:52:57] \"GET /_dash-component-suites/dash_core_components/async-plotlyjs.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "# assume you have a \"long-form\" data frame\n",
    "\n",
    "df = yf.download(\"ba\", start=\"2017-01-01\", end=\"2021-07-29\").reset_index()\n",
    "fig = px.line(df, x='Date', y=\"Close\")\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Hello Dash'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Dash: A web application framework for Python.\n",
    "    '''),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='example-graph',\n",
    "        figure=fig\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False, port=8070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the closing price history\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Close Price History')\n",
    "plt.plot(df['Close'])\n",
    "plt.xlabel('Date',fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Dash Framework - stock price visualization demo\n",
    "import pandas_datareader.data as web\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import datetime\n",
    "\n",
    "# First the layout\n",
    "app = dash.Dash()\n",
    "app.title = \"Stock Visualization\"\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1('Stock Visualization Dashboard'),\n",
    "    html.H4('Please enter the stock name'),\n",
    "    dcc.Input(id=\"input\", value='', type='text'),\n",
    "    html.Div(id=\"output-graph\")\n",
    "])\n",
    "\n",
    "# Second the interaction with the user\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id=\"output-graph\", component_property='children'),\n",
    "    [Input(component_id=\"input\", component_property=\"value\")]\n",
    ")\n",
    "def update_value(input_data):\n",
    "    start = datetime.datetime(2012, 1, 1)\n",
    "    end = datetime.datetime.now()\n",
    "    df = yf.download(input_data, start=\"2017-01-01\", end=\"2021-07-29\").reset_index()\n",
    "    #df = web.DataReader(input_data, 'yahoo', start, end)\n",
    "    \n",
    "    return dcc.Graph(id=\"demo\", figure={'df': [{'x': df.index, 'y': df.Close, 'type': 'line', 'name': input_data}, ], 'layout': {'title': input_data}})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False, port=8051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new datafram with only the \"close column\"\n",
    "data = df.filter(['Close'])\n",
    "#Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "#Get the nubmer of rows to train the model on\n",
    "training_data_len = math.ceil( len(dataset) *.8) # math.ceil is to round up the numbers, training data is 80%\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MinMaxScaler from sklearn to scale the data betweek 0 and 1\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training datae set\n",
    "#create the scaled training date set\n",
    "train_data = scaled_data[0:training_data_len, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into x_train and y_train data sets\n",
    "x_train=[] #training feature\n",
    "y_train = [] #targt varible\n",
    "for i in range(60,len(train_data)):\n",
    "    x_train.append(train_data[i-60:i,0]) # not including i\n",
    "    y_train.append(train_data[i,0])# 61st value\n",
    "    if i<= 60:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert x_train and y_train to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data into the shape accepted by the LSTM\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the LSTM network model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1 \n",
    "model.add(LSTM(units=50, return_sequences=True,input_shape=(x_train.shape[1],1))) #50 Neurons\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "\n",
    "#Output layers\n",
    "model.add(Dense(units=25))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(x_train, y_train, batch_size = 1, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the testing data set\n",
    "# Crete a new array containing scaled valueds from index 1543 to 2003\n",
    "test_data = scaled_data[training_data_len -60:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data sets x_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test =  dataset[training_data_len : , : ] #Get all of the rows from index 1603 to the rest and all of the columns (in this case it's only column 'Close'), so 2003 - 1603 = 400 rows of data\n",
    "for i in range(60,len(test_data)):\n",
    "    x_test.append(test_data[i-60:i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to a numpy array\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data into the shape accepted by the LSTM\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the models predicted price values\n",
    "predictions = model.predict(x_test) \n",
    "predictions = scaler.inverse_transform(predictions)#Undo scaling\n",
    "real = scaler.inverse_transform(y_test.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root mean squrared erro(RMSE)--how accurate the model to predit the response, the standard deviatation of the residules. \n",
    "rmse=np.sqrt(np.mean(((predictions- y_test)**2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot/Create the data for the graph\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the data\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the valid (actural  and predicted price)\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the quote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the quote\n",
    "apple_quote = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2021-07-29')\n",
    "#Create a new dataframe\n",
    "new_df = apple_quote.filter(['Close'])\n",
    "#Get teh last 60 day closing price \n",
    "last_60_days = new_df[-60:].values\n",
    "#Scale the data to be values between 0 and 1\n",
    "last_60_days_scaled = scaler.transform(last_60_days)\n",
    "#Create an empty list\n",
    "X_test = []\n",
    "#Append teh past 60 days\n",
    "X_test.append(last_60_days_scaled)\n",
    "#Convert the X_test data set to a numpy array\n",
    "X_test = np.array(X_test)\n",
    "#Reshape the data\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "#Get the predicted scaled price\n",
    "pred_price = model.predict(X_test)\n",
    "#undo the scaling \n",
    "pred_price = scaler.inverse_transform(pred_price)\n",
    "print(pred_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the quote\n",
    "apple_quote2 = web.DataReader('AAPL', data_source='yahoo', start='2019-12-18', end='2021-07-29')\n",
    "print(apple_quote2['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hvplot_dev]",
   "language": "python",
   "name": "conda-env-hvplot_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
