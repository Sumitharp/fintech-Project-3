{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# **Sentiment Analysis for stock and price trend indicator**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Input the stock ticker for which you want sentiment analysis**\r\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Input the ticker\r\n",
                "\r\n",
                "tickers=['tsla']"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Steps for the sentiment analysis-price movement.\r\n",
                "\r\n",
                "- ***BeautifulSoup Library***\r\n",
                "    - Here BeautifulSoup library is used for webscrapping the news table from the website 'https://finviz.com/quote.ashx?t='\r\n",
                "    - Using inspect on the webpage we can locate table-id which is then used to scrappe tr (tablerow).\r\n",
                "    - The news headlines are then converted into a dataframe which is used for sentiment analysis.\r\n",
                "- ***NLTK VADER Library***\r\n",
                "    -  NLTK VADER for sentiment analysis is used to find the neutral, postive, negative and compound sentiment for each headline. \r\n",
                "    - The compound values are then aggregated date-wise to get a meanscore dataframe.\r\n",
                "- ***Yfinance Library***\r\n",
                "    - Yfinance is used to obtain the stock prices for the ticker and S&P500, NASDAQ, DOW30 index closing values.\r\n",
                "    - A 2wk (week) period is considered for the price charts so that we can compare the price movements with the sentiment score. \r\n",
                "    - Important to remember that the sentiment score of t0 is seen in the price movement of t1\r\n",
                "- ***Dash Plotly Express Library***\r\n",
                "    - Plotly express is used to create that charts for sentiment analysis and price movements.\r\n",
                "    - Dash app is used to create a web page which can display charts on a web page and the user can interact with the chart and Dash interacts with the python code and displays the updated chart. \r\n",
                "    "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#for the sentiment analysis\r\n",
                "from urllib.request import urlopen, Request\r\n",
                "from bs4 import BeautifulSoup\r\n",
                "import os\r\n",
                "import pandas as pd\r\n",
                "import dash\r\n",
                "import dash_core_components as dcc\r\n",
                "import dash_html_components as html\r\n",
                "from dash.dependencies import Input, Output\r\n",
                "import pandas as pd\r\n",
                "import plotly.express as px\r\n",
                "from jupyter_dash import JupyterDash\r\n",
                "\r\n",
                "# NLTK VADER for sentiment analysis\r\n",
                "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
                "# tickers=['tsla']\r\n",
                "finwiz_url = 'https://finviz.com/quote.ashx?t='\r\n",
                "\r\n",
                "# Ticker news\r\n",
                "\r\n",
                "news_tables = {}\r\n",
                "# tickers = ticker2\r\n",
                "for ticker in tickers:\r\n",
                "    url = finwiz_url + ticker\r\n",
                "    req = Request(url=url,headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0'}) \r\n",
                "    response = urlopen(req)    \r\n",
                "    # Read the contents of the file into 'html'\r\n",
                "    html = BeautifulSoup(response)\r\n",
                "    # Find 'news-table' in the Soup and load it into 'news_table'\r\n",
                "    news_table = html.find(id='news-table')\r\n",
                "    # Add the table to our dictionary\r\n",
                "    news_tables[ticker] = news_table\r\n",
                "\r\n",
                "parsed_news = []\r\n",
                "\r\n",
                "# Iterate through the news\r\n",
                "for file_name, news_table in news_tables.items():\r\n",
                "    # Iterate through all tr tags in 'news_table'\r\n",
                "    for x in news_table.findAll('tr'):\r\n",
                "        # read the text from each tr tag into text\r\n",
                "        # get text from a only\r\n",
                "        text = x.a.get_text() \r\n",
                "        # splite text in the td tag into a list \r\n",
                "        date_scrape = x.td.text.split()\r\n",
                "        # if the length of 'date_scrape' is 1, load 'time' as the only element\r\n",
                "\r\n",
                "        if len(date_scrape) == 1:\r\n",
                "            time = date_scrape[0]\r\n",
                "            \r\n",
                "        # else load 'date' as the 1st element and 'time' as the second    \r\n",
                "        else:\r\n",
                "            date = date_scrape[0]\r\n",
                "            time = date_scrape[1]\r\n",
                "        # Extract the ticker from the file name, get the string up to the 1st '_'  \r\n",
                "        ticker = file_name.split('_')[0]\r\n",
                "        \r\n",
                "        # Append ticker, date, time and headline as a list to the 'parsed_news' list\r\n",
                "        parsed_news.append([ticker, date, time, text])\r\n",
                "        \r\n",
                "# Instantiate the sentiment intensity analyzer\r\n",
                "vader = SentimentIntensityAnalyzer()\r\n",
                "\r\n",
                "# Set column names\r\n",
                "columns = ['ticker', 'date', 'time', 'headline']\r\n",
                "\r\n",
                "# Convert the parsed_news list into a DataFrame called 'parsed_and_scored_news'\r\n",
                "parsed_and_scored_news = pd.DataFrame(parsed_news, columns=columns)\r\n",
                "\r\n",
                "# Iterate through the headlines and get the polarity scores using vader\r\n",
                "scores = parsed_and_scored_news['headline'].apply(vader.polarity_scores).tolist()\r\n",
                "\r\n",
                "# # Convert the 'scores' list of dicts into a DataFrame\r\n",
                "scores_df = pd.DataFrame(scores)\r\n",
                "\r\n",
                "# # Join the DataFrames of the news and the list of dicts\r\n",
                "parsed_and_scored_news = parsed_and_scored_news.join(scores_df, rsuffix='_right')\r\n",
                "\r\n",
                "# # Convert the date column from string to datetime\r\n",
                "parsed_and_scored_news['date'] = pd.to_datetime(parsed_and_scored_news.date).dt.date\r\n",
                "\r\n",
                "# parsed_and_scored_news.head(50)\r\n",
                "\r\n",
                "# Group by date and ticker columns from scored_news and calculate the mean\r\n",
                "mean_scores = parsed_and_scored_news.groupby(['ticker','date']).mean()\r\n",
                "# Unstack the column ticker\r\n",
                "mean_scores1 = mean_scores.unstack()\r\n",
                "# Get the cross-section of compound in the 'columns' axis\r\n",
                "mean_scores11 = mean_scores1.xs('compound', axis=\"columns\").transpose()\r\n",
                "#Create the fig sentiment compound scores\r\n",
                "sentifig=px.bar(mean_scores11,barmode='group',title= 'Compound sentiment scores of news aticles')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import dash\r\n",
                "import dash_core_components as dcc\r\n",
                "import dash_html_components as html\r\n",
                "from dash.dependencies import Input, Output\r\n",
                "import pandas as pd\r\n",
                "import plotly.express as px\r\n",
                "\r\n",
                "from jupyter_dash import JupyterDash\r\n",
                "\r\n",
                "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\r\n",
                "\r\n",
                "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\r\n",
                "\r\n",
                "# Code for creating the price charts -- 2 charts for stocks and 1 chart for index\r\n",
                "\r\n",
                "import plotly.express as px\r\n",
                "import plotly.graph_objects as go\r\n",
                "import yfinance as yf\r\n",
                "\r\n",
                "# Stock price charts for the inputed tickers\r\n",
                "\r\n",
                "stock = yf.download(tickers[0],period='2wk' ,interval = \"1d\").reset_index()\r\n",
                "figprice = px.line(stock, x='Date', y=\"Close\")\r\n",
                "# stock2 = yf.download(tickers[1],period='2wk' ,interval = \"1d\").reset_index()\r\n",
                "# zzzz = px.line(stock2, x='Date', y=\"Close\")\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "# Index Chart for S&P 500, NASDAQ, DOW30 \r\n",
                "\r\n",
                "index1 = yf.download(\"^GSPC ^IXIC ^DJI\",period='2wk' ,interval = \"1d\")\r\n",
                "closeidx=index1['Close'].reset_index()\r\n",
                "closeidx['SP500_change']=closeidx['^GSPC'].pct_change()\r\n",
                "closeidx['NASDAQ_change']=closeidx['^IXIC'].pct_change()\r\n",
                "closeidx['DOW30_change']=closeidx['^DJI'].pct_change()\r\n",
                "# closeidx\r\n",
                "figindex = px.line(closeidx, x='Date',y=['SP500_change','NASDAQ_change','DOW30_change'])\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "app.layout = html.Div(children=[\r\n",
                "    # All elements from the top of the page\r\n",
                "    html.Div([\r\n",
                "        html.Div([\r\n",
                "            html.H1(children='Sentiments Chart'),\r\n",
                "\r\n",
                "            html.Div(children='''\r\n",
                "                Sentiment analysis for stocks\r\n",
                "            '''),\r\n",
                "\r\n",
                "            dcc.Graph(\r\n",
                "                id='graph1',\r\n",
                "                figure=sentifig\r\n",
                "            ),  \r\n",
                "        ], className='six columns'),\r\n",
                "        html.Div([\r\n",
                "            html.H1(children='Price Chart '),\r\n",
                "\r\n",
                "            html.Div(children='''\r\n",
                "                Price chart for stocks\r\n",
                "            '''),\r\n",
                "\r\n",
                "            dcc.Graph(\r\n",
                "                id='graph2',\r\n",
                "                figure=figprice\r\n",
                "            ),  \r\n",
                "        ], className='six columns'),\r\n",
                "    ], className='row'),\r\n",
                "    # New Div for all elements in the new 'row' of the page\r\n",
                "    html.Div([\r\n",
                "        html.H1(children='Index Chart'),\r\n",
                "\r\n",
                "        html.Div(children='''\r\n",
                "            Chart shows the percentage change over last 2 weeks\r\n",
                "        '''),\r\n",
                "\r\n",
                "        dcc.Graph(\r\n",
                "            id='graph3',\r\n",
                "            figure=figindex\r\n",
                "        ),  \r\n",
                "    ], className='row'),\r\n",
                "])\r\n",
                "\r\n",
                "if __name__ == '__main__':\r\n",
                "    app.run_server(debug=False, port = 8293)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[*********************100%***********************]  1 of 1 completed\n",
                        "[*********************100%***********************]  3 of 3 completed\n",
                        "Dash is running on http://127.0.0.1:8293/\n",
                        "\n",
                        "Dash is running on http://127.0.0.1:8293/\n",
                        "\n",
                        " * Serving Flask app \"__main__\" (lazy loading)\n",
                        " * Environment: production\n",
                        "   WARNING: This is a development server. Do not use it in a production deployment.\n",
                        "   Use a production WSGI server instead.\n",
                        " * Debug mode: off\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        " * Running on http://127.0.0.1:8293/ (Press CTRL+C to quit)\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:21] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:22] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:22] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:22] \"\u001b[37mGET /_favicon.ico?v=1.19.0 HTTP/1.1\u001b[0m\" 200 -\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:34] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:35] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:35] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
                        "127.0.0.1 - - [02/Aug/2021 19:26:35] \"\u001b[37mGET /_favicon.ico?v=1.19.0 HTTP/1.1\u001b[0m\" 200 -\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('project3': conda)"
        },
        "interpreter": {
            "hash": "5d4c6269effcd4d3ef5f9a2e39285257dbec2e7fbb3a11a1f54b6b1fe87dc19e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}